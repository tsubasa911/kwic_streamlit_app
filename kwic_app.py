import streamlit as st
import spacy
import re
from collections import defaultdict
from nltk.corpus import wordnet as wn
import nltk

# å¿…è¦ã«å¿œã˜ã¦ WordNet ã‚’åˆå›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
try:
    wn.synsets("test")
except:
    nltk.download("wordnet")
    nltk.download("omw-1.4")

# --- NLPãƒ¢ãƒ‡ãƒ« ---
nlp = spacy.load("en_core_web_sm")

# --- å¤šè¨€èªUI ---
LANGS = {
    "en": {
        "title": "KWIC Explorer for English Learners",
        "input_mode": "Input Mode",
        "text_input": "Type or paste English text below:",
        "file_upload": "Or upload a .txt file:",
        "keyword": "Keyword to search",
        "context_width": "Context width (number of words)",
        "pos_filter": "POS Filter",
        "entity_filter": "Entity Filter",
        "search": "Search",
        "no_results": "No matching results found.",
        "results": "KWIC Results",
        "dictionary": "ğŸ“˜ Dictionary Definitions (WordNet)"
    },
    "ja": {
        "title": "è‹±èªå­¦ç¿’è€…ã®ãŸã‚ã®KWICæ¤œç´¢ãƒ„ãƒ¼ãƒ«",
        "input_mode": "å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰",
        "text_input": "è‹±èªã®æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
        "file_upload": "ã¾ãŸã¯.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼š",
        "keyword": "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
        "context_width": "å‰å¾Œã®å˜èªæ•°",
        "pos_filter": "å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        "entity_filter": "å›ºæœ‰è¡¨ç¾ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        "search": "æ¤œç´¢ã™ã‚‹",
        "no_results": "è©²å½“ã™ã‚‹ä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚",
        "results": "KWICçµæœ",
        "dictionary": "ğŸ“˜ èªç¾©ï¼ˆWordNetã‚ˆã‚Šï¼‰"
    }
}

# --- è¨€èªåˆ‡æ›¿ ---
lang = st.sidebar.selectbox("Language / è¨€èª", options=["en", "ja"])
L = LANGS[lang]

# --- ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º ---
st.title(L["title"])

# --- å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ ---
input_mode = st.radio(L["input_mode"], ["Text", "File"])
text = ""

if input_mode == "Text":
    text = st.text_area(L["text_input"], height=200)
else:
    uploaded_file = st.file_uploader(L["file_upload"], type=["txt"])
    if uploaded_file is not None:
        text = uploaded_file.read().decode("utf-8")

# --- æ¤œç´¢æ¡ä»¶ ---
keyword = st.text_input(L["keyword"])
context_width = st.slider(L["context_width"], 1, 10, 5)
pos_options = ["ALL", "NOUN", "VERB", "ADJ", "ADV"]
entity_options = ["ALL", "PERSON", "ORG", "GPE", "PRODUCT", "DATE"]
selected_pos = st.selectbox(L["pos_filter"], pos_options)
selected_entity = st.selectbox(L["entity_filter"], entity_options)

# --- æ¤œç´¢å®Ÿè¡Œ ---
if st.button(L["search"]) and keyword and text:
    doc = nlp(text)
    tokens = [token for token in doc]
    results = []

    for i, token in enumerate(tokens):
        if token.text.lower() == keyword.lower():
            left = " ".join(t.text for t in tokens[max(0, i - context_width):i])
            center = token.text
            right = " ".join(t.text for t in tokens[i + 1:i + 1 + context_width])

            # POS & ENTITYãƒ•ã‚£ãƒ«ã‚¿
            if selected_pos != "ALL" and token.pos_ != selected_pos:
                continue
            if selected_entity != "ALL":
                ent = token.ent_type_ if token.ent_type_ else "O"
                if ent != selected_entity:
                    continue

            results.append((left, center, right, token.pos_, token.ent_type_))

    # --- KWICçµæœè¡¨ç¤º ---
    if results:
        st.subheader(L["results"])
        for left, center, right, pos, ent in results:
            st.markdown(
                f"... {left} **{center}** {right} ...  \n"
                f"*POS:* `{pos}`  |  *ENTITY:* `{ent if ent else 'None'}`"
            )
    else:
        st.warning(L["no_results"])

    # --- WordNetè¾æ›¸è¡¨ç¤º ---
    if keyword:
        st.subheader(L["dictionary"])
        synsets = wn.synsets(keyword)
        if synsets:
            for i, syn in enumerate(synsets[:5]):
                st.markdown(f"**{i+1}. {syn.name()}**")
                st.write(f"- Definition: {syn.definition()}")
                if syn.examples():
                    st.write(f"- Example: _{syn.examples()[0]}_")
                if syn.lemmas():
                    synonyms = set(lemma.name() for lemma in syn.lemmas())
                    st.write(f"- Synonyms: {', '.join(synonyms)}")
                st.markdown("---")
        else:
            st.info("No definitions found in WordNet.")
